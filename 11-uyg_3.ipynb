{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ÖRNEK 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "from pandas.tools.plotting import scatter_matrix\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://goo.gl/mLmoIz\"\n",
    "names = ['sepal-length', 'sepal-width', 'petal-length', 'petal-width', 'class']\n",
    "dataset = read_csv(url, names=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.groupby('class').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.hist(figsize=(8,8))\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_matrix(dataset,figsize=(12,12))\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.pairplot(dataset, hue=\"class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\", palette=\"muted\")\n",
    "\n",
    "# Load the example iris dataset\n",
    "iris = sns.load_dataset(\"iris\")\n",
    "\n",
    "# \"Melt\" the dataset to \"long-form\" or \"tidy\" representation\n",
    "iris = pd.melt(iris, \"species\", var_name=\"measurement\")\n",
    "\n",
    "# Draw a categorical scatterplot to show each observation\n",
    "sns.swarmplot(x=\"measurement\", y=\"value\", hue=\"species\",\n",
    "              palette=[\"r\", \"c\", \"y\"], data=iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = dataset.values\n",
    "X = array[:,0:4]\n",
    "Y = array[:,4]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y,test_size=0.20, random_state=77)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "models.append(('LR', LogisticRegression()))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVM', SVC()))\n",
    "\n",
    "sonuc = []\n",
    "isim = []\n",
    "for isim, model in models:\n",
    "    kfold = KFold(n_splits=10, random_state=0)\n",
    "    cv_results = cross_val_score(model, X_train, Y_train, cv=kfold)\n",
    "    sonuc.append(cv_results)\n",
    "    names.append(isim)\n",
    "    msg = \"%s: %f (%f)\" % (isim, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, Y_train)\n",
    "predictions = knn.predict(X_test)\n",
    "print(accuracy_score(Y_test, predictions))\n",
    "print(confusion_matrix(Y_test, predictions))\n",
    "print(classification_report(Y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ÖRNEK 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from numpy import arange\n",
    "from matplotlib import pyplot\n",
    "from pandas import read_csv\n",
    "from pandas import set_option\n",
    "from pandas.tools.plotting import scatter_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()\n",
    "\n",
    "bos = pd.DataFrame(boston.data)\n",
    "bos.columns = boston.feature_names\n",
    "bos['PRICE'] = boston.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bos.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bos.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_option('precision', 2)\n",
    "print(bos.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "j=bos.corr()\n",
    "f, ax = plt.subplots(figsize=(9, 9))\n",
    "sns.heatmap(j, annot=True, linewidths=.5, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bos.hist(sharex=False, sharey=False, xlabelsize=1, ylabelsize=1,figsize=(9, 9))\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_matrix(bos,figsize=(9, 9))\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = bos.values\n",
    "X = array[:,0:13]\n",
    "Y = array[:,13]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y,test_size=0.2, random_state=55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "models.append(('LR', LinearRegression()))\n",
    "models.append(('LASSO', Lasso()))\n",
    "models.append(('KNN', KNeighborsRegressor()))\n",
    "models.append(('CART', DecisionTreeRegressor()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sonuc = []\n",
    "isim = []\n",
    "for isim, model in models:\n",
    "    kfold = KFold(n_splits=10, random_state=7)\n",
    "    cv_results = cross_val_score(model, X_train, Y_train, cv=kfold)\n",
    "    sonuc.append(cv_results)\n",
    "    names.append(isim)\n",
    "    msg = \"%s: %f (%f)\" % (isim, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines = []\n",
    "pipelines.append(('Scaled_LR', Pipeline([('Scaler', StandardScaler()),('LR',LinearRegression())])))\n",
    "pipelines.append(('Scaled_LASSO', Pipeline([('Scaler', StandardScaler()),('LASSO',Lasso())])))\n",
    "pipelines.append(('Scaled_KNN', Pipeline([('Scaler', StandardScaler()),('KNN',KNeighborsRegressor())])))\n",
    "pipelines.append(('Scaled_CART', Pipeline([('Scaler', StandardScaler()),('CART',DecisionTreeRegressor())])))\n",
    "\n",
    "sonuc = []\n",
    "isim = []\n",
    "for isim, model in pipelines:\n",
    "    kfold = KFold(n_splits=10, random_state=7)\n",
    "    cv_results1 = cross_val_score(model, X_train, Y_train, cv=kfold)\n",
    "    sonuc.append(cv_results1)\n",
    "    names.append(isim)\n",
    "    msg = \"%s: %f (%f)\" % (isim, cv_results1.mean(), cv_results1.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(X_train)\n",
    "rescaledX = scaler.transform(X_train)\n",
    "k_values = numpy.array([1,3,5,7,9,11,13,15,17,19,21])\n",
    "param_grid = dict(n_neighbors=k_values)\n",
    "model = KNeighborsRegressor()\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=kfold)\n",
    "grid_result = grid.fit(rescaledX, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"En iyi: %f %s ile\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) : %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "models.append(('GBM',GradientBoostingRegressor(n_estimators=150)))\n",
    "models.append(('RF',RandomForestRegressor(n_estimators=150)))\n",
    "models.append(('ET',ExtraTreesRegressor(n_estimators=150)))\n",
    "\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    kfold = KFold(n_splits=10, random_state=7)\n",
    "    cv_results = cross_val_score(model, X_train, Y_train, cv=kfold)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = dict(n_estimators=numpy.array([50,100,150,200,250,300,350,400]))\n",
    "model = GradientBoostingRegressor(random_state=7)\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=kfold)\n",
    "grid_result = grid.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"En iyi: %f ,%s ile\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) : %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### En iyi modeli artık test verisine uygulama zamanı"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GradientBoostingRegressor(random_state=7, n_estimators=150)\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "tahmin_train = model.predict(X_train)\n",
    "  \n",
    "print('R-kare (test): %.4f\\n' % r2_score(Y_test, tahmin_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ÖRNEK 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from matplotlib import pyplot\n",
    "from pandas import read_csv\n",
    "from pandas import set_option\n",
    "from pandas.tools.plotting import scatter_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://goo.gl/NXoJfR\"\n",
    "dataset = read_csv(url, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_option('display.width', 100)\n",
    "set_option('precision', 2)\n",
    "print(dataset.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_option('precision', 2)\n",
    "print(dataset.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.groupby(60).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.hist(sharex=False, sharey=False, xlabelsize=1, ylabelsize=1,figsize=(9, 9))\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = pyplot.figure(figsize=(19, 19))\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(dataset.corr(), vmin=-1, vmax=1, interpolation='none')\n",
    "fig.colorbar(cax)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "j=dataset.corr()\n",
    "f, ax = plt.subplots(figsize=(19, 19))\n",
    "sns.heatmap(j, annot=True, linewidths=.5, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = dataset.values\n",
    "X = array[:,0:60].astype(float)\n",
    "Y = array[:,60]\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y,test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "models.append(('LR', LogisticRegression(solver='lbfgs')))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVM', SVC(gamma='scale')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    kfold = KFold(n_splits=10, random_state=7)\n",
    "    cv_results = cross_val_score(model, X_train, Y_train, cv=kfold)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines = []\n",
    "pipelines.append(('Scaled_LR', Pipeline([('Scaler', StandardScaler()),('LR',LogisticRegression(solver='lbfgs'))])))\n",
    "pipelines.append(('Scaled_KNN', Pipeline([('Scaler', StandardScaler()),('KNN',KNeighborsClassifier())])))\n",
    "pipelines.append(('Scaled_NB', Pipeline([('Scaler', StandardScaler()),('NB',GaussianNB())])))\n",
    "pipelines.append(('Scaled_SVM', Pipeline([('Scaler', StandardScaler()),('SVM', SVC())])))\n",
    "results = []\n",
    "names = []\n",
    "for name, model in pipelines:\n",
    "    kfold = KFold(n_splits=10, random_state=7)\n",
    "    cv_results = cross_val_score(model, X_train, Y_train, cv=kfold)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(X_train)\n",
    "rescaledX = scaler.transform(X_train)\n",
    "neighbors = [1,3,5,7,9,11,13,15,17,19,21]\n",
    "param_grid = dict(n_neighbors=neighbors)\n",
    "model = KNeighborsClassifier()\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=kfold)\n",
    "grid_result = grid.fit(rescaledX, Y_train)\n",
    "print(\"En iyi: %f , %s ile\"  % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) : %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(X_train)\n",
    "rescaledX = scaler.transform(X_train)\n",
    "c_values = [0.1, 0.3, 0.5, 0.7, 0.9, 1.0, 1.3, 1.5, 1.7, 2.0]\n",
    "kernel_values = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "param_grid = dict(C=c_values, kernel=kernel_values)\n",
    "model = SVC(gamma='scale')\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=kfold)\n",
    "grid_result = grid.fit(rescaledX, Y_train)\n",
    "print(\"En iyi: %f , %s ile\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) : %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensembles = []\n",
    "ensembles.append(('GBM', GradientBoostingClassifier(n_estimators=100)))\n",
    "ensembles.append(('RF', RandomForestClassifier(n_estimators=100)))\n",
    "ensembles.append(('ET', ExtraTreesClassifier(n_estimators=100)))\n",
    "results = []\n",
    "names = []\n",
    "for name, model in ensembles:\n",
    "    kfold = KFold(n_splits=10, random_state=7)\n",
    "    cv_results = cross_val_score(model, X_train, Y_train, cv=kfold)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### modellerin gücünü ölçme zamanı"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVC(gamma='scale',C=2.0,kernel='rbf')\n",
    "model.fit(rescaledX, Y_train)\n",
    "# estimate accuracy on validation dataset\n",
    "rescaledValidationX = scaler.transform(X_test)\n",
    "predictions = model.predict(rescaledValidationX)\n",
    "print(accuracy_score(Y_test, predictions))\n",
    "print(confusion_matrix(Y_test, predictions))\n",
    "print(classification_report(Y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
